{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0d28577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Zhichao Carton\n",
      "[nltk_data]     Zeng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Zhichao Carton\n",
      "[nltk_data]     Zeng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Zhichao Carton\n",
      "[nltk_data]     Zeng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "import texthero\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa3f66",
   "metadata": {},
   "source": [
    "<span style=\"font-size:22px;font-family:sans-serif\"> Now do text cleaning... </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aa689f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('train.csv')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d956151",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px;font-family:sans-serif;color:LightSeaGreen\">1. Remove space characters (and other special characters here, if any, in the future), also switching all characters to lower case... </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a2d13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_n(ss):\n",
    "    ss = ss.replace(\"\\t\", \" \")\n",
    "    return ss.replace(\"\\n\", \" \")\n",
    "\n",
    "data_train['text_n'] = data_train['full_text'].apply(remove_n)\n",
    "\n",
    "texthero_pipe = [#texthero.preprocessing.fillna,\n",
    "                    texthero.preprocessing.lowercase\n",
    "                    #texthero.preprocessing.remove_digits,\n",
    "                    #texthero.preprocessing.remove_punctuation,\n",
    "                    #texthero.preprocessing.remove_diacritics\n",
    "                    ]\n",
    "data_train['text_n'] = texthero.clean(data_train['text_n'], pipeline = texthero_pipe) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d17fbf8",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px;font-family:sans-serif;color:LightSeaGreen\">2. Dealing with contractions... </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9b2ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['text_nc'] = data_train['text_n'].apply(contractions.fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb7aa25",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px;font-family:sans-serif;color:LightSeaGreen\">3. Lemmatize: combine ifferent forms of the same word... </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "765644dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       i think that student would benefit from learni...\n",
       "1       when a problem is a change you have to let it ...\n",
       "2       dear principal if you change the school policy...\n",
       "3       the best time in life is when you become yours...\n",
       "4       small act of kindness can impact in other peop...\n",
       "                              ...                        \n",
       "3906    i believe using cellphone in class for educati...\n",
       "3907    working alone student do not have to argue wit...\n",
       "3908    a problem is a chance for you to do your best ...\n",
       "3909    many people disagree with albert schweitzer s ...\n",
       "3910    do you think that failure is the main thing fo...\n",
       "Name: text_lmtz, Length: 3911, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# tokenize, lemmatize, then detokenize\n",
    "def lmtz(ss):\n",
    "    tokens_list = ss.apply(lambda x: tokenizer.tokenize(x))\n",
    "    new_tokens_list = []\n",
    "    for tokens in (tokens_list):\n",
    "        new_tokens = []\n",
    "        for token in (tokens): \n",
    "            new_tokens.append(lemmatizer.lemmatize(token))\n",
    "        new_tokens_list.append(TreebankWordDetokenizer().detokenize(new_tokens))\n",
    "    return new_tokens_list\n",
    "\n",
    "data_train['text_lmtz'] = pd.Series(lmtz(data_train['text_nc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557fb70",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px;font-family:sans-serif;color:LightSeaGreen\">4. Spelling correction by comparing with nltk. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "11a5742b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m temp_ls, err_cnt \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m case \u001b[38;5;129;01min\u001b[39;00m data_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_nc\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 39\u001b[0m     txt, err \u001b[38;5;241m=\u001b[39m \u001b[43mcount_mis_spelling_and_correct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     temp_ls\u001b[38;5;241m.\u001b[39mappend(txt)\n\u001b[0;32m     41\u001b[0m     err_cnt\u001b[38;5;241m.\u001b[39mappend(err)\n",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36mcount_mis_spelling_and_correct\u001b[1;34m(essay)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(wd) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m7\u001b[39m:                                            \u001b[38;5;66;03m# only apply the spelling correction to len > 7 words\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wd \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m correct_words:\n\u001b[1;32m---> 28\u001b[0m         wd_new \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect_spelling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m         cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36mcorrect_spelling\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_numbers(word):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m         temp \u001b[38;5;241m=\u001b[39m [(jaccard_distance(\u001b[38;5;28mset\u001b[39m(ngrams(word, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     11\u001b[0m                                   \u001b[38;5;28mset\u001b[39m(ngrams(w, \u001b[38;5;241m2\u001b[39m))),w)\n\u001b[0;32m     12\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m correct_words \u001b[38;5;28;01mif\u001b[39;00m w[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m==\u001b[39mword[\u001b[38;5;241m0\u001b[39m]]   \u001b[38;5;66;03m# so first letter must be correct\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28msorted\u001b[39m(temp, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m val:val[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_numbers(word):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m         temp \u001b[38;5;241m=\u001b[39m [(jaccard_distance(\u001b[38;5;28mset\u001b[39m(ngrams(word, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     11\u001b[0m                                   \u001b[38;5;28mset\u001b[39m(ngrams(w, \u001b[38;5;241m2\u001b[39m))),w)\n\u001b[1;32m---> 12\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m correct_words \u001b[38;5;28;01mif\u001b[39;00m w[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[43mword\u001b[49m[\u001b[38;5;241m0\u001b[39m]]   \u001b[38;5;66;03m# so first letter must be correct\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28msorted\u001b[39m(temp, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m val:val[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correct_words = words.words()\n",
    "\n",
    "def has_numbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "# if a word is not found in words.words(), will return the 'most similar' word in the dictionary using jaccard metric\n",
    "def correct_spelling(word):  \n",
    "    if not has_numbers(word):\n",
    "        try:\n",
    "            temp = [(jaccard_distance(set(ngrams(word, 2)),\n",
    "                                      set(ngrams(w, 2))),w)\n",
    "                    for w in correct_words if w[0]==word[0]]   # so first letter must be correct\n",
    "            return str(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "        except Exception as e: \n",
    "            print (word)\n",
    "            print (e)\n",
    "    else:\n",
    "        return word\n",
    "    return word\n",
    "    \n",
    "def count_mis_spelling_and_correct(essay):\n",
    "    essay_tok = tokenizer.tokenize(essay)\n",
    "    cnt = 0\n",
    "    essay_new = []\n",
    "    for wd in essay_tok:\n",
    "        if len(wd) > 7:                                            # only apply the spelling correction to len > 7 words\n",
    "            if wd not in correct_words:\n",
    "                wd_new = correct_spelling(wd)\n",
    "                cnt += 1\n",
    "            else:\n",
    "                wd_new = wd\n",
    "        else:\n",
    "            wd_new = wd\n",
    "        essay_new.append(wd_new) \n",
    "    return str(essay), cnt\n",
    "\n",
    "temp_ls, err_cnt = [], []\n",
    "for case in data_train['text_nc']:\n",
    "    txt, err = count_mis_spelling_and_correct(case)\n",
    "    temp_ls.append(txt)\n",
    "    err_cnt.append(err)\n",
    "    \n",
    "data_train['text_spelling'] = pd.Series(temp_ls)\n",
    "data_train['no. spelling error'] = pd.Series(err_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9069247",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px;font-family:sans-serif;color:LightSeaGreen\">Removing Stopwords... </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5e22f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       i think that students would benefit from learn...\n",
       "1       when a problem is a change you have to let it ...\n",
       "2       dear, principal  if you change the school poli...\n",
       "3       the best time in life is when you become yours...\n",
       "4       small act of kindness can impact in other peop...\n",
       "                              ...                        \n",
       "3906    i believe using cellphones in class for educat...\n",
       "3907    working alone, students do not have to argue w...\n",
       "3908    \"a problem is a chance for you to do your best...\n",
       "3909    many people disagree with albert schweitzer's ...\n",
       "3910    do you think that failure is the main thing fo...\n",
       "Name: text_spelling, Length: 3911, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['text_spelling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8be9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
