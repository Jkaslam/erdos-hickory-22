{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "h5T6rJA3w0XL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Flatten,Reshape\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import csv\n",
    "import nltk\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yif2s43w-Amb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.layers import Input,Concatenate,Dropout,Dense,BatchNormalization,Conv1D\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import scipy\n",
    "from tensorflow.keras.initializers import he_normal,glorot_normal\n",
    "from tensorflow.keras.regularizers import l1,l2\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint,LearningRateScheduler,ReduceLROnPlateau\n",
    "from time import time\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input,BatchNormalization,Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "import random as rn\n",
    "import string\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.initializers import glorot_uniform,glorot_normal\n",
    "from tensorflow.keras.layers import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "coVpb7Lg-T1R",
    "outputId": "c3bb1cfa-5ba8-4eb9-bfab-2203324f2369"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading the training data\n",
    "training_data=pd.read_csv(\"./data/train.csv\")\n",
    "display(training_data.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing. \n",
    "\n",
    "Preprocessing includes removing spaces, special characters, contractions and stop words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gl8fSjkIxPiP",
    "outputId": "a3965b3c-7b32-461c-ccb9-778f582ca8ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3911/3911 [00:02<00:00, 1457.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "def decontractions(phrase):\n",
    "   \n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "#preprocessing: replacing special characters and space and make text lowercase\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "stopwords = stopwords.words('english')\n",
    "def preprocess(text_col,stopword):\n",
    "    preprocessed = []\n",
    "    for sentence in tqdm(text_col.values):\n",
    "        # Replace \"carriage return\" with \"space\".\n",
    "        sentence=str(sentence)\n",
    "        sent = sentence.replace('\\\\r', ' ')\n",
    "        # Replace \"quotes\" with \"space\".\n",
    "        sent = sent.replace('\\\\\"', ' ')\n",
    "        # Replace \"line feed\" with \"space\".\n",
    "        sent = sent.replace('\\\\n', ' ')\n",
    "         # Replace characters between words with \"space\".\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "        #remove stop words\n",
    "        #decontraction\n",
    "        sent=decontractions(sent)\n",
    "        if stopword:\n",
    "            sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "        else:\n",
    "            sent = ' '.join(e for e in sent.split())\n",
    "        # to lowercase\n",
    "        preprocessed.append(sent.lower().strip())\n",
    "    return preprocessed\n",
    "training_data['full_text']=preprocess(training_data['full_text'],stopword=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>i think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>when a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>dear principal if u change the school policy o...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>the best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  i think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  when a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  dear principal if u change the school policy o...       3.0   \n",
       "3  003885A45F42  the best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-17b3TaLxxTF",
    "outputId": "b72ca6a1-c6a8-42b5-fbd0-fc2d4a5737ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3128, 1) (3128, 6)\n"
     ]
    }
   ],
   "source": [
    "#Train -test split, 20% of the data for validation set.\n",
    "y=training_data[['cohesion','syntax','vocabulary','phraseology','grammar','conventions']]\n",
    "X=training_data.drop(['text_id','cohesion','syntax','vocabulary','phraseology','grammar','conventions'],axis=1)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.20)\n",
    "print(X_train.shape,y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HFyKJfx4x2dB",
    "outputId": "367e8b83-84d7-449b-dcb9-6bd275645a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3128, 200) (783, 200)\n"
     ]
    }
   ],
   "source": [
    "#padding to make all the vectors of the same length\n",
    "\n",
    "def pad_text(text,tokenizer,max_len):\n",
    "    return pad_sequences(tokenizer.texts_to_sequences(text),maxlen=max_len,padding='post')\n",
    "\n",
    "\n",
    "def text_padding(train,test,max_len):\n",
    "    vocab=5000\n",
    "    token=Tokenizer()\n",
    "    token.fit_on_texts(train)\n",
    "    padded_train_text=pad_text(train,token,max_len)\n",
    "    padded_test_text=pad_text(test,token,max_len)\n",
    "    return padded_train_text,padded_test_text,token\n",
    "comm_len=200\n",
    "train_com_pad,test_com_pad,token_com= text_padding(X_train['full_text'],X_test['full_text'],comm_len)\n",
    "\n",
    "print(train_com_pad.shape,test_com_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eraKdj-rx-W_"
   },
   "outputs": [],
   "source": [
    "def generate_embedding_matrix(token):\n",
    "    embedding_path='../../Python Scripts/crawl-300d-2M.vec' #pre trained FastText English word vectors released by FB\n",
    "    embedding_size=300\n",
    "    vocab_size=5000\n",
    "    embedding_index={}\n",
    "    with open(embedding_path, 'r',encoding=\"utf8\") as f:\n",
    "         for line in f:\n",
    "                values = line.rstrip().rsplit(' ')\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embedding_index[word] = coefs\n",
    "    num_words = len(token.word_index) + 1\n",
    "    embedding_matrix = np.zeros((num_words, embedding_size))\n",
    "    for word, i in token.word_index.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the embedding matrix or use the already stored one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNBuWe-gyR1d",
    "outputId": "277609e5-75b0-4584-a2d0-8a589935e169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18870, 300)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'spe' is an invalid keyword argument for tofile()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m embedding_comm \u001b[38;5;241m=\u001b[39m generate_embedding_matrix(token_com)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(embedding_comm\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 4\u001b[0m \u001b[43membedding_comm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtofile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEmbedded_matrix_trained_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mspe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'spe' is an invalid keyword argument for tofile()"
     ]
    }
   ],
   "source": [
    "# generating the embedding matrix containing (if not already generated)\n",
    "embedding_comm = generate_embedding_matrix(token_com)\n",
    "print(embedding_comm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the embedded matrix for trained\n",
    "np.savetxt('./data/Embedded_matrix_trained_data.csv',embedding_comm,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18870, 300)\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.0175     -0.2189      0.0353     ... -0.28459999  0.0509\n",
      "   0.0229    ]\n",
      " [ 0.0231      0.017       0.0157     ...  0.0744     -0.1118\n",
      "   0.0963    ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.2287     -0.41420001  0.37360001 ... -0.1402     -0.39649999\n",
      "  -0.2001    ]\n",
      " [-0.2219     -0.29179999  0.1426     ... -0.0482     -0.1573\n",
      "   0.16670001]]\n"
     ]
    }
   ],
   "source": [
    "#Use the already stored embedded matrix for the trained data\n",
    "embedding_comm = np.loadtxt('./data/Embedded_matrix_trained_data.csv', delimiter=',')\n",
    "#print(embedding_comm1.shape)\n",
    "#print(embedding_comm1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vqnevNmx56pZ"
   },
   "outputs": [],
   "source": [
    "#reshaping the data \n",
    "X_train=[train_com_pad,train_com_pad]\n",
    "X_test=[test_com_pad,test_com_pad]\n",
    "y_train=np.array(2.0*y_train,dtype=np.float64)\n",
    "y_test=np.array(2.0*y_test, dtype=np.float64)\n",
    "\n",
    "# mean columwise rmse\n",
    "def mcrmse(y_true, y_pred):\n",
    "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n",
    "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vqrDfRu76DkI"
   },
   "outputs": [],
   "source": [
    "# We will use the Adam optimizer \n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "def LSTM_CNN1D(comm_len,token_com):\n",
    "    drop_lstm = 0.25\n",
    "    drop_dense = 0.25\n",
    "    num_lstm=150\n",
    "    input_1 = Input(shape=(comm_len,),name = 'input_comment_1')\n",
    "    embedding_layer_1 = Embedding(len(token_com.word_index) + 1,300,weights=[embedding_comm],input_length=comm_len,trainable=False,dtype=tf.float32)(input_1)\n",
    "    conv_1_1 = Conv1D(64,3,strides=1, padding='same',activation='relu')(embedding_layer_1)\n",
    "    lstm_1_1 = LSTM(64,dropout=drop_lstm,return_sequences=True,dtype=tf.float32)(embedding_layer_1)\n",
    "    concate_1 = keras.layers.Concatenate(axis=-1)([conv_1_1, lstm_1_1])\n",
    "    flatten_1 = Flatten()(concate_1)\n",
    "\n",
    "    # creating layers for parent comment data\n",
    "    input_2 = Input(shape=(comm_len,),name = 'input_comment_2')\n",
    "    embedding_layer_2 = Embedding(len(token_com.word_index) + 1,300,weights=[embedding_comm],input_length=comm_len,trainable=False,dtype=tf.float32)(input_2)\n",
    "    conv_1_1 = Conv1D(128,3,strides=1, padding='same',activation='relu')(embedding_layer_2)\n",
    "    lstm_1_2 =LSTM(128,dropout=drop_lstm,return_sequences=True,dtype=tf.float32)(embedding_layer_2)\n",
    "    concate_2 = keras.layers.Concatenate(axis=-1)([conv_1_1, lstm_1_2])\n",
    "    flatten_2 = Flatten()(concate_2)\n",
    "\n",
    "    \n",
    "    concatenated_layer = keras.layers.concatenate([flatten_1,flatten_2],axis=-1)\n",
    "\n",
    "    # creating further layers\n",
    "    x = Dense(128, activation = 'relu',kernel_initializer=glorot_uniform(seed=42))(concatenated_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(64, activation = 'relu',kernel_initializer=glorot_uniform(seed=42))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation = 'relu',kernel_initializer=glorot_uniform(seed=42))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(16, activation = 'relu',kernel_initializer=glorot_uniform(seed=42))(x)\n",
    "    output = Dense(6,activation='linear')(x)\n",
    "    model = Model(inputs = [input_1,input_2], outputs = [output])\n",
    "    model.compile(optimizer=adam, loss = mcrmse, metrics = mcrmse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ec8AGYpG6SYm",
    "outputId": "3cac99b7-601c-4e9d-cc4c-d6b743e5588a"
   },
   "outputs": [],
   "source": [
    "model=LSTM_CNN1D(comm_len,token_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7jeLdKTq6rD1"
   },
   "outputs": [],
   "source": [
    "#reduce_lr reduces the learning rate when the metric has stoppes improving for 2 epochs. \n",
    "#Using EarlyStopping to stop the calculation upon reaching enough accuracy\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_mcrmse', factor = 0.25, patience = 2, verbose = 1)\n",
    "earlystop = EarlyStopping(monitor = 'val_mcrmse',  mode=\"min\",min_delta = 0, patience = 25,verbose = 1)\n",
    "callbacks = [reduce_lr,earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "crrtOMqr6xJS",
    "outputId": "a7e2087b-140f-4f2e-9b46-a3542eb73ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "98/98 [==============================] - 61s 504ms/step - loss: 4.9104 - mcrmse: 4.9050 - val_loss: 9.4293 - val_mcrmse: 9.4258 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "98/98 [==============================] - 55s 560ms/step - loss: 2.1857 - mcrmse: 2.1833 - val_loss: 2.4329 - val_mcrmse: 2.4300 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "98/98 [==============================] - 57s 581ms/step - loss: 1.1664 - mcrmse: 1.1667 - val_loss: 1.6861 - val_mcrmse: 1.6799 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "98/98 [==============================] - 54s 555ms/step - loss: 0.9935 - mcrmse: 0.9935 - val_loss: 1.5343 - val_mcrmse: 1.5318 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "98/98 [==============================] - 55s 560ms/step - loss: 0.9070 - mcrmse: 0.9069 - val_loss: 1.3278 - val_mcrmse: 1.3276 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "98/98 [==============================] - 63s 643ms/step - loss: 0.8840 - mcrmse: 0.8841 - val_loss: 1.2622 - val_mcrmse: 1.2578 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "98/98 [==============================] - 57s 578ms/step - loss: 0.8373 - mcrmse: 0.8372 - val_loss: 1.3166 - val_mcrmse: 1.3142 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.8004 - mcrmse: 0.8004\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "98/98 [==============================] - 74s 758ms/step - loss: 0.8004 - mcrmse: 0.8004 - val_loss: 1.2695 - val_mcrmse: 1.2701 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "98/98 [==============================] - 59s 598ms/step - loss: 0.7453 - mcrmse: 0.7451 - val_loss: 1.1692 - val_mcrmse: 1.1686 - lr: 2.5000e-04\n",
      "Epoch 10/200\n",
      "98/98 [==============================] - 54s 555ms/step - loss: 0.7031 - mcrmse: 0.7030 - val_loss: 1.2088 - val_mcrmse: 1.2082 - lr: 2.5000e-04\n",
      "Epoch 11/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6910 - mcrmse: 0.6913\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "98/98 [==============================] - 76s 778ms/step - loss: 0.6910 - mcrmse: 0.6913 - val_loss: 1.1814 - val_mcrmse: 1.1807 - lr: 2.5000e-04\n",
      "Epoch 12/200\n",
      "98/98 [==============================] - 55s 564ms/step - loss: 0.6568 - mcrmse: 0.6567 - val_loss: 1.1816 - val_mcrmse: 1.1810 - lr: 6.2500e-05\n",
      "Epoch 13/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6602 - mcrmse: 0.6607\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "98/98 [==============================] - 64s 652ms/step - loss: 0.6602 - mcrmse: 0.6607 - val_loss: 1.1697 - val_mcrmse: 1.1697 - lr: 6.2500e-05\n",
      "Epoch 14/200\n",
      "98/98 [==============================] - 94s 961ms/step - loss: 0.6367 - mcrmse: 0.6368 - val_loss: 1.1728 - val_mcrmse: 1.1727 - lr: 1.5625e-05\n",
      "Epoch 15/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6494 - mcrmse: 0.6492\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "98/98 [==============================] - 62s 635ms/step - loss: 0.6494 - mcrmse: 0.6492 - val_loss: 1.1735 - val_mcrmse: 1.1734 - lr: 1.5625e-05\n",
      "Epoch 16/200\n",
      "98/98 [==============================] - 92s 946ms/step - loss: 0.6358 - mcrmse: 0.6365 - val_loss: 1.1720 - val_mcrmse: 1.1721 - lr: 3.9063e-06\n",
      "Epoch 17/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6397 - mcrmse: 0.6397\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "98/98 [==============================] - 63s 640ms/step - loss: 0.6397 - mcrmse: 0.6397 - val_loss: 1.1713 - val_mcrmse: 1.1714 - lr: 3.9063e-06\n",
      "Epoch 18/200\n",
      "98/98 [==============================] - 57s 579ms/step - loss: 0.6224 - mcrmse: 0.6232 - val_loss: 1.1716 - val_mcrmse: 1.1717 - lr: 9.7656e-07\n",
      "Epoch 19/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6486 - mcrmse: 0.6487\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "98/98 [==============================] - 89s 907ms/step - loss: 0.6486 - mcrmse: 0.6487 - val_loss: 1.1719 - val_mcrmse: 1.1720 - lr: 9.7656e-07\n",
      "Epoch 20/200\n",
      "98/98 [==============================] - 75s 764ms/step - loss: 0.6260 - mcrmse: 0.6260 - val_loss: 1.1730 - val_mcrmse: 1.1731 - lr: 2.4414e-07\n",
      "Epoch 21/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6437 - mcrmse: 0.6440\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "98/98 [==============================] - 62s 629ms/step - loss: 0.6437 - mcrmse: 0.6440 - val_loss: 1.1715 - val_mcrmse: 1.1716 - lr: 2.4414e-07\n",
      "Epoch 22/200\n",
      "98/98 [==============================] - 100s 1s/step - loss: 0.6304 - mcrmse: 0.6306 - val_loss: 1.1720 - val_mcrmse: 1.1720 - lr: 6.1035e-08\n",
      "Epoch 23/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6315 - mcrmse: 0.6319\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "98/98 [==============================] - 56s 574ms/step - loss: 0.6315 - mcrmse: 0.6319 - val_loss: 1.1723 - val_mcrmse: 1.1723 - lr: 6.1035e-08\n",
      "Epoch 24/200\n",
      "98/98 [==============================] - 75s 763ms/step - loss: 0.6462 - mcrmse: 0.6463 - val_loss: 1.1729 - val_mcrmse: 1.1729 - lr: 1.5259e-08\n",
      "Epoch 25/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6399 - mcrmse: 0.6402\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "98/98 [==============================] - 59s 605ms/step - loss: 0.6399 - mcrmse: 0.6402 - val_loss: 1.1719 - val_mcrmse: 1.1720 - lr: 1.5259e-08\n",
      "Epoch 26/200\n",
      "98/98 [==============================] - 73s 750ms/step - loss: 0.6391 - mcrmse: 0.6392 - val_loss: 1.1712 - val_mcrmse: 1.1714 - lr: 3.8147e-09\n",
      "Epoch 27/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6375 - mcrmse: 0.6377\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "98/98 [==============================] - 66s 672ms/step - loss: 0.6375 - mcrmse: 0.6377 - val_loss: 1.1721 - val_mcrmse: 1.1722 - lr: 3.8147e-09\n",
      "Epoch 28/200\n",
      "98/98 [==============================] - 674s 7s/step - loss: 0.6286 - mcrmse: 0.6283 - val_loss: 1.1716 - val_mcrmse: 1.1717 - lr: 9.5367e-10\n",
      "Epoch 29/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6496 - mcrmse: 0.6499\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
      "98/98 [==============================] - 47s 484ms/step - loss: 0.6496 - mcrmse: 0.6499 - val_loss: 1.1711 - val_mcrmse: 1.1712 - lr: 9.5367e-10\n",
      "Epoch 30/200\n",
      "98/98 [==============================] - 46s 474ms/step - loss: 0.6397 - mcrmse: 0.6395 - val_loss: 1.1712 - val_mcrmse: 1.1713 - lr: 2.3842e-10\n",
      "Epoch 31/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6149 - mcrmse: 0.6149\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n",
      "98/98 [==============================] - 48s 491ms/step - loss: 0.6149 - mcrmse: 0.6149 - val_loss: 1.1711 - val_mcrmse: 1.1712 - lr: 2.3842e-10\n",
      "Epoch 32/200\n",
      "98/98 [==============================] - 47s 477ms/step - loss: 0.6452 - mcrmse: 0.6449 - val_loss: 1.1707 - val_mcrmse: 1.1709 - lr: 5.9605e-11\n",
      "Epoch 33/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6380 - mcrmse: 0.6383\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.4901161901614834e-11.\n",
      "98/98 [==============================] - 47s 479ms/step - loss: 0.6380 - mcrmse: 0.6383 - val_loss: 1.1716 - val_mcrmse: 1.1717 - lr: 5.9605e-11\n",
      "Epoch 34/200\n",
      "98/98 [==============================] - 70s 721ms/step - loss: 0.6409 - mcrmse: 0.6415 - val_loss: 1.1714 - val_mcrmse: 1.1715 - lr: 1.4901e-11\n",
      "Epoch 34: early stopping\n"
     ]
    }
   ],
   "source": [
    "hitory1=model.fit(x=X_train,y=y_train,epochs=200,batch_size=32,validation_data=(X_test, y_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model and weights for future \n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "model_json = model.to_json()\n",
    "with open(\"./data/LSTM_model_final.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"./data/LSTM_weights_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "json_file=open('./data/LSTM_model_final.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"./data/LSTM_weights_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 3s 119ms/step\n"
     ]
    }
   ],
   "source": [
    "#predicted y\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbA64eigmjAM",
    "outputId": "edd7d61e-83fe-41af-ed0e-5f67b163c72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error in cohesion is 1.4861864027452998\n",
      "mean squared error in syntax is 1.3162939278051802\n",
      "mean squared error in vocabulary is 1.136270210567518\n",
      "mean squared error in phraseology is 1.415051596539844\n",
      "mean squared error in grammar is 1.5284098875756265\n",
      "mean squared error in conventions is 1.4524118242881146\n"
     ]
    }
   ],
   "source": [
    "# calculating mean squared errors\n",
    "categories=training_data.columns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "for i in range(6):\n",
    "    error = mean_squared_error(y_test[:,i],y_pred[:,i])\n",
    "    print(\"mean squared error in\",categories[i+2],\"is\",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
